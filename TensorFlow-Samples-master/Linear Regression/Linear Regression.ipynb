{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>HousingMedianAge</th>\n",
       "      <th>TotalRooms</th>\n",
       "      <th>TotalBedrooms</th>\n",
       "      <th>Population</th>\n",
       "      <th>Households</th>\n",
       "      <th>MedianIncomeValue</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Longitude  Latitude  HousingMedianAge  TotalRooms  TotalBedrooms  \\\n",
       "0    -122.23     37.88                41         880            129   \n",
       "1    -122.22     37.86                21        7099           1106   \n",
       "2    -122.24     37.85                52        1467            190   \n",
       "3    -122.25     37.85                52        1274            235   \n",
       "4    -122.25     37.85                52        1627            280   \n",
       "\n",
       "   Population  Households  MedianIncomeValue  MedianHouseValue  \n",
       "0         322         126             8.3252            452600  \n",
       "1        2401        1138             8.3014            358500  \n",
       "2         496         177             7.2574            352100  \n",
       "3         558         219             5.6431            341300  \n",
       "4         565         259             3.8462            342200  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_data_1 = pd.read_csv('cal_housing_data with headers.csv')\n",
    "df_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make a numpy array from the dataframe\n",
    "data = np.array([x for x in df_data_1.values])\n",
    "\n",
    "# Separate the 'predictors' (aka 'features') from the dependent variable (aka 'label') \n",
    "# that we will learn how to predict\n",
    "housing_data = np.delete(data, 8, axis=1)\n",
    "housing_target = np.delete(data, slice(0, 8), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m, n = housing_data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Make the compute graph\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float64, name=\"X\")\n",
    "XT = tf.transpose(X)\n",
    "y = tf.constant(housing_target.reshape(-1, 1), dtype=tf.float64, name=\"y\")\n",
    "\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "# Run the compute graph\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.59402294e+06],\n",
       "       [ -4.28237438e+04],\n",
       "       [ -4.25767219e+04],\n",
       "       [  1.15630387e+03],\n",
       "       [ -8.18164928e+00],\n",
       "       [  1.13410689e+02],\n",
       "       [ -3.85350953e+01],\n",
       "       [  4.83082868e+01],\n",
       "       [  4.02485142e+04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For fun, show the linear regression model (i.e. the coefficients of the linear equation)\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: ../datasets/Linear Regression: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# Make a subdirectory in which to save the model\n",
    "!mkdir \"../datasets/Linear Regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model = tf.Variable(tf.constant(theta_value, dtype=tf.float64), name=\"model\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as saver_sess:\n",
    "    init.run()\n",
    "    theta_value = model.eval()\n",
    "    save_path = saver.save(saver_sess, \"../datasets/Linear Regression/Linear Regression.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression.ckpt.data-00000-of-00001\r\n",
      "Linear Regression.ckpt.index\r\n",
      "Linear Regression.ckpt.meta\r\n",
      "checkpoint\r\n"
     ]
    }
   ],
   "source": [
    "# List the files that comprise the saved model\n",
    "!ls \"../datasets/Linear Regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../datasets/Linear Regression/Linear Regression.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Restore the saved model \n",
    "# NOTE: This should run on inference service initialization, not on every inference\n",
    "\n",
    "sess_restore = tf.Session()\n",
    "\n",
    "saver = tf.train.import_meta_graph('../datasets/Linear Regression/Linear Regression.ckpt.meta')\n",
    "saver.restore(sess_restore,tf.train.latest_checkpoint('../datasets/Linear Regression/'))\n",
    "\n",
    "theta_value = sess_restore.run('model:0')\n",
    "\n",
    "sess_restore.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.59402294e+06],\n",
       "       [ -4.28237438e+04],\n",
       "       [ -4.25767219e+04],\n",
       "       [  1.15630387e+03],\n",
       "       [ -8.18164928e+00],\n",
       "       [  1.13410689e+02],\n",
       "       [ -3.85350953e+01],\n",
       "       [  4.83082868e+01],\n",
       "       [  4.02485142e+04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For fun, show the linear regression model again\n",
    "theta_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we'll do an inference to predict a value with the model\n",
    "# We will use house_data[0] as if it had been received as input to the inference service\n",
    "\n",
    "# TODO: This can be rewritten as TensorFlow code at some point, but that would be more typical of \n",
    "#       larger models. At only 9 iterations, this would likely be slower as TensorFlow code\n",
    "\n",
    "# Start by setting the predicted value equal to the linear equation's constant term\n",
    "predicted_value = theta_value[0][0]\n",
    "\n",
    "# Get the coefficients of the features (i.e. exclude the constant term accounted for above)\n",
    "coefficients = theta_value[1:]\n",
    "\n",
    "# For each feature (independent variable), add to the predicted value the product\n",
    "# of the coefficient for the feature (c = theta_value[j+1]) and the j^th feature of\n",
    "# the inference service input data (represented by housing_data[0])\n",
    "for j, c in enumerate(coefficients):\n",
    "    predicted_value += c[0] * housing_data[0][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411111.09606514324"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For fun, show the predicted value\n",
    "predicted_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is some earlier code written to do the predictions on all items of training data,\n",
    "# but this batch processing of predictions is NOT the baseline use case exepcted for CP10 and CP47 services\n",
    "\n",
    "# Start by setting each predicted value equal to the linear equation's constant term\n",
    "predicted_values = np.full((m), theta_value[0][0])\n",
    "\n",
    "# Get the coefficients of the features (i.e. exclude the constant term accounted for above)\n",
    "coefficients = theta_value[1:]\n",
    "\n",
    "# For each of the m rows of housing data, update the predicted value (y) as follows:\n",
    "    # For each feature (independent variable), add to the predicted value the product\n",
    "    # of the coefficient for the feature (c = theta_value[j+1]) and the i^th row's\n",
    "    # housing data value for the jth feature\n",
    "\n",
    "for i, x in enumerate(housing_data):\n",
    "    for j, c in enumerate(coefficients):\n",
    "        predicted_values[i] += c * x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 411111.09606514,  416144.49078677,  380432.65417531, ...,\n",
       "         25026.16974547,   37991.19625605,   55550.98309601])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For fun, show the batch of predicted values\n",
    "predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## For when you want to wipe out the training and do it again\n",
    "# !rm -rf \"../datasets/Linear Regression\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 452600.,  358500.,  352100., ...,   92300.,   84700.,   89400.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a flattened version of the house prices to use in R2 calculations below\n",
    "y_actual = np.ndarray.flatten(housing_target)\n",
    "y_actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63710562292234463"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate R^2 using the scikit learn function. This measures the quality of the regression model.\n",
    "from sklearn.metrics import r2_score\n",
    "R2 = r2_score(y_actual, predicted_values)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206855.81690891474"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll do it manually to help understand how R^2 characterizes regression model quality\n",
    "# We start with the mean of the actual dependent variable\n",
    "y_bar = np.mean(y_actual)\n",
    "y_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274831981936881.9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll compute the data set variance from the mean (total sum of squared differences)\n",
    "SStot = 0.0\n",
    "for y_i in y_actual:\n",
    "    diff = float(y_i - y_bar)\n",
    "    SStot += (diff * diff)\n",
    "SStot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175097001050335.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we compute the amount that the regression model's predicted values vary from the mean.\n",
    "# This is the sum of squared differences between the predicted values and the mean\n",
    "SSreg = 0.0\n",
    "for f_i in predicted_values:\n",
    "    diff = float(f_i - y_bar)\n",
    "    SSreg += (diff * diff)\n",
    "SSreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6371056229203638"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The R squared is just the ratio. It gives the percentage of the variance from the mean \n",
    "# that is accounted for by using the regression model to predict values instead of just\n",
    "# always using the mean as the predicted value for any observation in the group.\n",
    "R_squared = SSreg / SStot\n",
    "R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99734980886003.83"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A second way to think about this is to consider the amount of remaining error,\n",
    "# i.e. the amount of remaining or 'residual' variance between the actual data points \n",
    "# and the regression model's predicted values\n",
    "SSres = 0.0\n",
    "for i, f_i in enumerate(predicted_values):\n",
    "    diff = float(f_i - y_actual[i])\n",
    "    SSres += (diff * diff)\n",
    "SSres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6371056229223386"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So R squared can also be computed based on the percentage of leftover (residual) variance\n",
    "R_squared = 1.0 - SSres / SStot\n",
    "R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
